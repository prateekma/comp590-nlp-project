{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMc7Cv1ft956wem1SAAjsU4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eADkS_JRXsKa","executionInfo":{"status":"ok","timestamp":1681770010324,"user_tz":240,"elapsed":21901,"user":{"displayName":"Connor Vines","userId":"02323794181031401041"}},"outputId":"7388e58c-2932-4a75-d3ca-4d8635b43f43"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","source":["import os\n","import nltk\n","from nltk.tokenize import word_tokenize\n","from tqdm import tqdm"],"metadata":{"id":"JbvJIYfEXxEU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["nltk.download('stopwords')\n","nltk.download('punkt')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dlxr3afsXy_6","executionInfo":{"status":"ok","timestamp":1681770015527,"user_tz":240,"elapsed":617,"user":{"displayName":"Connor Vines","userId":"02323794181031401041"}},"outputId":"702a310c-cd8a-4500-a750-e4cd53c05a6b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["def process_file(file_name):\n","  with open(file_name, \"r\") as file:\n","    text = file.read()\n","  return text"],"metadata":{"id":"zLyYLOHgX1rI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def choose_data(n):\n","  # Choose single movie (Kung Fu Panda) as data\n","  if n == 1:\n","    file_names = [ \"/content/gdrive/My Drive/Colab Notebooks/Movie Corpus Analysis/imsdb_scenes_dialogs_nov_2015/imsdb_scenes_dialogs_nov_2015/dialogs/Family/kungfupanda_dialog.txt\" ]\n","    data = process_file(file_names[0])\n","  # Choose 2 movies (Die Hard and Die Hard 2) as data\n","  if n == 2:\n","    file_names = [\"/content/gdrive/My Drive/Colab Notebooks/Movie Corpus Analysis/imsdb_scenes_dialogs_nov_2015/imsdb_scenes_dialogs_nov_2015/dialogs/Action/diehard_dialog.txt\",\n","                  \"/content/gdrive/My Drive/Colab Notebooks/Movie Corpus Analysis/imsdb_scenes_dialogs_nov_2015/imsdb_scenes_dialogs_nov_2015/dialogs/Action/diehard2_dialog.txt\"]\n","    data = process_file(file_names[0]) + ' STARTTOKEN ENDTOKEN ' + process_file(file_names[1])\n","\n","  # Choose 3 movies (all Starwars) as data\n","  if n == 3:\n","    file_names = [\"/content/gdrive/My Drive/Colab Notebooks/Movie Corpus Analysis/imsdb_scenes_dialogs_nov_2015/imsdb_scenes_dialogs_nov_2015/dialogs/Action/starwarsanewhope_dialog.txt\",\n","                  \"/content/gdrive/My Drive/Colab Notebooks/Movie Corpus Analysis/imsdb_scenes_dialogs_nov_2015/imsdb_scenes_dialogs_nov_2015/dialogs/Action/starwarstheempirestrikesback_dialog.txt\",\n","                  \"/content/gdrive/My Drive/Colab Notebooks/Movie Corpus Analysis/imsdb_scenes_dialogs_nov_2015/imsdb_scenes_dialogs_nov_2015/dialogs/Action/starwarsattackoftheclones_dialog.txt\"]\n","    data = \"\"\n","    for file_name in file_names:\n","      data += ' STARTTOKEN '\n","      data += process_file(file_name)\n","      data += ' ENDTOKEN '\n","\n","\n","  # TRY OTHER DATASET... maybe Friday the 13th or Nightmare on Elm... any series with a ton of movies\n","  # Or Halloween\n","  if n == 4:\n","    file_names = [\"/content/gdrive/My Drive/Colab Notebooks/Movie Corpus Analysis/raw_texts/raw_texts/Harry Potter and the Sorcerer s Stone_0241527.txt\",\n","                  \"/content/gdrive/My Drive/Colab Notebooks/Movie Corpus Analysis/raw_texts/raw_texts/Harry Potter and the Chamber of Secrets_0295297.txt\",\n","                  \"/content/gdrive/My Drive/Colab Notebooks/Movie Corpus Analysis/raw_texts/raw_texts/Harry Potter and the Prisoner of Azkaban_0304141.txt\",\n","                  \"/content/gdrive/My Drive/Colab Notebooks/Movie Corpus Analysis/raw_texts/raw_texts/Harry Potter and the Goblet of Fire_0330373.txt\",\n","                  \"/content/gdrive/My Drive/Colab Notebooks/Movie Corpus Analysis/raw_texts/raw_texts/Harry Potter and the Half Blood Prince_0417741.txt\",\n","                  \"/content/gdrive/My Drive/Colab Notebooks/Movie Corpus Analysis/raw_texts/raw_texts/Harry Potter and the Order of the Phoenix_0373889.txt\",\n","                  \"/content/gdrive/My Drive/Colab Notebooks/Movie Corpus Analysis/raw_texts/raw_texts/Harry Potter and the Deathly Hallows Part 1_0926084.txt\"]\n","    data = \"\"\n","    for file_name in file_names:\n","      data += ' STARTTOKEN '\n","      data += process_file(file_name)\n","      data += ' ENDTOKEN '\n","\n","  return data"],"metadata":{"id":"UPFpFLrsX3Rh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data = choose_data(4)"],"metadata":{"id":"voxlmTEmX3a7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import re\n","\n","def remove_URLs_and_Numbers(text):\n","  text = re.sub(r'http\\S+', '', text)\n","  text = re.sub(r'\\d+', '', text)\n","  return text"],"metadata":{"id":"DA3GtTZiX47x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["text = remove_URLs_and_Numbers(data)"],"metadata":{"id":"jq8Szve0X6gj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokens = word_tokenize(text)"],"metadata":{"id":"vQZoSUfuX7py"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(tokens[:50])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cCKKm0SVX8WY","executionInfo":{"status":"ok","timestamp":1681770035550,"user_tz":240,"elapsed":4,"user":{"displayName":"Connor Vines","userId":"02323794181031401041"}},"outputId":"654387e0-26a0-4688-e8d7-45d675797e64"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['STARTTOKEN', 'HARRY', 'POTTER', 'AND', 'THE', 'SORCERER', '’', 'S', 'STONE', 'BR', 'eee', 'Screenplay', 'by', 'Steve', 'Kloves', 'Based', 'on', 'the', 'novel', 'by', 'J.K.', 'Rowling', 'Shooting', 'Draft', '//', 'Blue', 'Revision', '//', '-', 'Pink', 'Revision', '//', '.', 'Yellow', 'Revision', '//', 'Green', 'Revision', '//', 'Gold', 'Revision', '//', 'Buff', 'Revision', '//', '‘', 'Salmon', 'Revision', '//', 'Cherry']\n"]}]},{"cell_type":"code","source":["i=0\n","while i < len(tokens):\n","  if tokens[i] == 'STARTTOKEN':\n","    tokens[i] = '<s>'\n","  if tokens[i] == 'ENDTOKEN':\n","    tokens[i] = '</s>'\n","  if tokens[i] == '.':\n","    tokens[i] = '</s>'\n","    tokens.insert(i+1, '<s>')\n","  i += 1"],"metadata":{"id":"Xr3UG2ijX9LU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(tokens[:50])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yErhryuXX-zO","executionInfo":{"status":"ok","timestamp":1681770037555,"user_tz":240,"elapsed":10,"user":{"displayName":"Connor Vines","userId":"02323794181031401041"}},"outputId":"2aec78bf-0f76-4173-cdf2-3014c301e37f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s>', 'HARRY', 'POTTER', 'AND', 'THE', 'SORCERER', '’', 'S', 'STONE', 'BR', 'eee', 'Screenplay', 'by', 'Steve', 'Kloves', 'Based', 'on', 'the', 'novel', 'by', 'J.K.', 'Rowling', 'Shooting', 'Draft', '//', 'Blue', 'Revision', '//', '-', 'Pink', 'Revision', '//', '</s>', '<s>', 'Yellow', 'Revision', '//', 'Green', 'Revision', '//', 'Gold', 'Revision', '//', 'Buff', 'Revision', '//', '‘', 'Salmon', 'Revision', '//']\n"]}]},{"cell_type":"code","source":["from nltk.tokenize.sonority_sequencing import punctuation\n","from nltk.corpus import stopwords\n","import string\n","from nltk.stem import SnowballStemmer\n","\n","def remove_Stopwords_and_Punctuation_and_Stem(tokens):\n","  stemmer = SnowballStemmer(language='english')\n","  englishStopwords = stopwords.words('english')\n","  puncuation = string.punctuation\n","  # stemmer.stem(token)\n","  tokens = [ token.lower() for token in tokens if token not in englishStopwords and token not in punctuation ]\n","  return tokens"],"metadata":{"id":"Zm1tVC12X_oW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokens = remove_Stopwords_and_Punctuation_and_Stem(tokens)"],"metadata":{"id":"0cpcVsJtYA0k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(len(set(tokens)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Alt5tA8hYBhe","executionInfo":{"status":"ok","timestamp":1681770038786,"user_tz":240,"elapsed":3,"user":{"displayName":"Connor Vines","userId":"02323794181031401041"}},"outputId":"3c65ea4e-a665-4dbf-9e6c-47ab0efc900c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["13153\n"]}]},{"cell_type":"code","source":["lookup = {}\n","start_words = []\n","\n","for i in range(len(tokens)-4):\n","  context = ' '.join(tokens[i:i+4])\n","  next_token = tokens[i+4]\n","  if context not in lookup.keys():\n","    lookup[context] = {}\n","  if next_token not in lookup[context].keys():\n","    lookup[context][next_token] = 0\n","  if tokens[i] == '<s>':\n","    start_words.append(context)\n","  lookup[context][next_token] += 1"],"metadata":{"id":"FImRG-FOYCqQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(len(lookup))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cEW3tOqGYKz1","executionInfo":{"status":"ok","timestamp":1681770039353,"user_tz":240,"elapsed":6,"user":{"displayName":"Connor Vines","userId":"02323794181031401041"}},"outputId":"647ea08c-7654-4f5f-d2b4-d95da251e7f4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["160839\n"]}]},{"cell_type":"code","source":["for key in lookup.keys():\n","  count = 0\n","  for val in lookup[key]:\n","    count += lookup[key][val]\n","  for val in lookup[key]:\n","    lookup[key][val] /= count"],"metadata":{"id":"aN5DwCBrYMEI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(lookup)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Lo-TCv_TYNH2","executionInfo":{"status":"ok","timestamp":1681770040412,"user_tz":240,"elapsed":615,"user":{"displayName":"Connor Vines","userId":"02323794181031401041"}},"outputId":"3a3a9b07-9472-4f5b-b345-32b2177df115"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["IOPub data rate exceeded.\n","The notebook server will temporarily stop sending output\n","to the client in order to avoid crashing it.\n","To change this limit, set the config variable\n","`--NotebookApp.iopub_data_rate_limit`.\n","\n","Current values:\n","NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n","NotebookApp.rate_limit_window=3.0 (secs)\n","\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import numpy.random as rand\n","\n","def generate_sentences(num_sentences, lookup=lookup):\n","  context = rand.choice(start_words)\n","  sentence = context\n","  current_token = None\n","  num_stop_tokens = 0\n","  while num_stop_tokens < num_sentences:\n","\n","    probs = [ lookup[context][key] for key in lookup[context].keys() ]\n","    keys = [ key for key in lookup[context].keys() ]\n","    i = rand.multinomial(1,probs)\n","    \n","    index = 0\n","    for j in range(len(i)):\n","      if i[j] == 1:\n","        index = j\n","        break\n","    current_token = keys[index]\n","    context = ' '.join(context.split()[1:4]) + ' ' + current_token\n","    sentence = sentence + ' ' + current_token\n","    if current_token == '</s>':\n","      num_stop_tokens += 1\n","    \n","  return sentence"],"metadata":{"id":"Pm1UcndmYO8H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(generate_sentences(10))"],"metadata":{"id":"WRPg3HWqYZ_j","executionInfo":{"status":"ok","timestamp":1681771147354,"user_tz":240,"elapsed":199,"user":{"displayName":"Connor Vines","userId":"02323794181031401041"}},"outputId":"27253c2e-01f0-41fd-f412-c91b9ffc20f5","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["<s> ni intensely ginny did hear ores ginny blinks startled father ‘ fierce pole ... nods </s> <s> as mr. weasley pulls harry away others hover clipping b.g </s> <s> fred george fill cups steaming nog mrs. weasley ginny ferry plates food </s> <s> mrs. weasley are right harry dear you look like ’ going sick </s> <s> he great friend james </s> <s> lupin smiles wanly lifts sorry suitcase </s> <s> then stops </s> <s> there professor lupin stories mother know </s> <s> some even true </s> <s> but i ’ l wanting professor merrythought ’ old office water closet i formerly </s>\n"]}]}]}